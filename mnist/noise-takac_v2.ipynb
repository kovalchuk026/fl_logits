{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43b405cc-a8d3-456e-84bc-3a995aa95f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f593c86e-b59e-417d-aa31-0415aa6a8fcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| 30%   44C    P2              80W / 300W |   1297MiB / 49140MiB |      5%      Default |\n",
      "| 30%   31C    P8              28W / 300W |  13253MiB / 49140MiB |      0%      Default |\n",
      "| 30%   31C    P8              23W / 300W |     12MiB / 49140MiB |      0%      Default |\n",
      "| 30%   31C    P8              17W / 300W |  22353MiB / 49140MiB |      0%      Default |\n",
      "| 50%   75C    P2             292W / 300W |  35619MiB / 49140MiB |     96%      Default |\n",
      "| 42%   71C    P2             257W / 300W |   6769MiB / 49140MiB |    100%      Default |\n",
      "| 30%   45C    P2              88W / 300W |   4958MiB / 49140MiB |     27%      Default |\n",
      "| 30%   49C    P2              99W / 300W |   6060MiB / 49140MiB |     34%      Default |\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi | grep 300W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15f79735-c659-4631-9c89-d560a3ba2b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "pathPrefix =\"../data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1261199a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8fce3d20-015e-4918-a96a-21c0c2b8c0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "329d0e2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7d04bdb5e410>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = 0\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "9e726299",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class SimpleCNN(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "#         self.conv1 = nn.Conv2d(1, 16, 3, padding=1)\n",
    "#         self.fc = nn.Linear(16 * 28 * 28, 10)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = torch.relu(self.conv1(x))\n",
    "#         x = x.view(-1, 16 * 28 * 28)\n",
    "#         return self.fc(x)\n",
    "\n",
    "# from https://medium.com/@deepeshdeepakdd2/lenet-5-implementation-on-mnist-in-pytorch-c6f2ee306e37\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.feature = nn.Sequential(\n",
    "            #1\n",
    "            nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, stride=1, padding=2),   # 28*28->32*32-->28*28\n",
    "            nn.Tanh(),\n",
    "            nn.AvgPool2d(kernel_size=2, stride=2),  # 14*14\n",
    "            \n",
    "            #2\n",
    "            nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1),  # 10*10\n",
    "            nn.Tanh(),\n",
    "            nn.AvgPool2d(kernel_size=2, stride=2),  # 5*5\n",
    "            \n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=16*5*5, out_features=120),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(in_features=120, out_features=84),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(in_features=84, out_features=10),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.classifier(self.feature(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "872b1466",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_fixed_class_client_loaders(num_clients=4, k=5, batch_size=32):  #checked\n",
    "    \n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ])\n",
    "\n",
    "    dataset = datasets.MNIST(root=\"./data\", train=True, download=True, transform=transform)\n",
    "\n",
    "    # Build class indices\n",
    "    class_indices = defaultdict(list)\n",
    "    for idx, (_, label) in enumerate(dataset):\n",
    "        class_indices[label].append(idx)\n",
    "    \n",
    "    for c in class_indices:\n",
    "        np.random.shuffle(class_indices[c])\n",
    "\n",
    "    # Assign exactly k unique classes to each client\n",
    "    all_classes = np.arange(10)\n",
    "    client_classes = [np.random.choice(all_classes, size=k, replace=False) for _ in range(num_clients)]\n",
    "\n",
    "    client_indices = [[] for _ in range(num_clients)]\n",
    "\n",
    "    # Distribute samples of each class to clients that need it\n",
    "    for class_id in range(10):\n",
    "    \n",
    "        # Clients that selected this class\n",
    "        clients_with_class = [cid for cid, classes in enumerate(client_classes) if class_id in classes]\n",
    "        if not clients_with_class:\n",
    "            continue\n",
    "\n",
    "        # Split class data among those clients\n",
    "        splits = np.array_split(class_indices[class_id], len(clients_with_class))\n",
    "        for cid, split in zip(clients_with_class, splits):\n",
    "            client_indices[cid].extend(split.tolist())\n",
    "\n",
    "    client_loaders = []\n",
    "    for indices in client_indices:\n",
    "        if not indices:\n",
    "            indices = [0] \n",
    "        loader = DataLoader(\n",
    "            Subset(dataset, indices),\n",
    "            batch_size=batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=2,\n",
    "            pin_memory=True,\n",
    "            drop_last=True\n",
    "        )\n",
    "        client_loaders.append(loader)\n",
    "    return client_loaders, client_classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "id": "5e42f238",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_local(model, loader, optimizer, device, epochs=1, r=-1, lr = 0.01): #checked\n",
    "    model.train()\n",
    "    criterion = nn.CrossEntropyLoss()    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    for _ in range(epochs):\n",
    "        for j, (data, target) in enumerate(loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if r>=0:\n",
    "                if j>=r:\n",
    "                    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "352fa6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_server(server_model, avg_logits, common_data, optimizer, epochs=1): #checked\n",
    "    server_model.train()\n",
    "    criterion = nn.KLDivLoss(reduction=\"batchmean\")\n",
    "\n",
    "    for _ in range(epochs):\n",
    "        for x, y in zip(common_data, avg_logits):\n",
    "            optimizer.zero_grad()\n",
    "            log_prob = F.log_softmax(server_model(x), dim=-1)\n",
    "            loss = criterion(log_prob, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "f57793ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_loader, device): #checked\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "            total += target.size(0)\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "77d95ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_out_uncertain_logits(logits_list, threshold=1.2):  #checked\n",
    "    stacked = torch.stack(logits_list)        # [M, B, C]\n",
    "    # Compute entropy per model per sample\n",
    "    probs = F.softmax(stacked, dim=-1)        # [M, B, C]\n",
    "    entropy = -(probs * probs.log()).sum(dim=-1)   # [M, B]\n",
    "\n",
    "    # Mask: True if confident\n",
    "    mask = (entropy < threshold).float()      # [M, B]\n",
    "\n",
    "    # Expand mask to logits shape\n",
    "    mask_expanded = mask.unsqueeze(-1)        # [M, B, 1]\n",
    "\n",
    "    # Zero out uncertain logits\n",
    "    masked_logits = stacked * mask_expanded   # [M, B, C]\n",
    "\n",
    "    # Count how many models contributed per sample\n",
    "    denom = mask.sum(dim=0).unsqueeze(-1).clamp(min=1)  # [B, 1]\n",
    "\n",
    "    # Average only over confident models\n",
    "    avg_logits = masked_logits.sum(dim=0) / denom       # [B, C]\n",
    "\n",
    "    masked_probs = probs * mask_expanded\n",
    "    avg_probs = masked_probs.sum(dim=0) / denom\n",
    "    return avg_probs, torch.mean(entropy)\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "e211dd6b-73fa-43cf-a991-6ff2e327e5ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "ddd874ab-7511-4519-88f5-5fb2d5aff2b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b8c207-7f61-4e9d-ba33-468895d52de6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "b5c5be6a-9368-4b01-bc3a-7e00398aeeb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a9e046-1438-48a4-b0cc-803b4946d118",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "id": "31c71257",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_clients = 20\n",
    "batch_size = 64\n",
    "common_data_size = 512\n",
    "k = 2\n",
    "threshold = 3\n",
    "\n",
    "client_loaders, _ = create_fixed_class_client_loaders(num_clients, batch_size=batch_size, k=k)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# Create a subset with specific indices\n",
    "indices = list(range(len(test_dataset)))  # e.g., first 1000 samples\n",
    "np.random.shuffle(indices)\n",
    "testSubset = Subset(test_dataset, indices[:1000])\n",
    "commonSubset = Subset(test_dataset, indices[1000:])\n",
    "\n",
    "# Use with DataLoader\n",
    "test_loader = torch.utils.data.DataLoader(testSubset, batch_size=batch_size, shuffle=False)\n",
    "common_loader = torch.utils.data.DataLoader(commonSubset, batch_size=batch_size, shuffle=True,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "id": "263adb94-6a97-4dbd-9a2a-760a73990eb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "YS=[]\n",
    "for loader in client_loaders:\n",
    "    Y=[]\n",
    "    for x,y in loader:\n",
    "        Y.append(y)\n",
    "    YS.append(torch.cat(Y))\n",
    "Ys = torch.cat(YS)\n",
    "plt.hist(Ys,10);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "id": "e74967c8-0589-47e9-b7a7-89202308adda",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_models = [SimpleCNN().to(device) for _ in range(num_clients)]\n",
    "server_model = SimpleCNN().to(device)\n",
    "\n",
    "local_optimizers = [optim.Adam(m.parameters(), lr=0.01) for m in local_models]\n",
    "server_optimizer = optim.Adam(server_model.parameters(), lr=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "id": "b95b8d49-474d-4f5b-9c75-acf62b85ff87",
   "metadata": {},
   "outputs": [],
   "source": [
    "R=-1\n",
    "LR=0.01\n",
    "EPOCHS = 20\n",
    "criterion = nn.KLDivLoss(reduction=\"batchmean\")\n",
    "up = 1.1\n",
    "targetProb = 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "id": "16ef8c80-90b5-478d-9b7b-18095f4135a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterionCE = nn.CrossEntropyLoss()    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2068c674",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: 53.11111111111111% Server model accuracy on test set: 52.20%, local models average accuracy before copying: 19.42%\n"
     ]
    }
   ],
   "source": [
    "for r in range(2):\n",
    "    Pmax=[]\n",
    "    local_acc = []\n",
    "    for i, (model, loader, opt) in enumerate(zip(local_models, client_loaders, local_optimizers)):\n",
    "        train_local(model, loader, opt, device, epochs=EPOCHS, r=R, lr=LR)\n",
    "        if i % 5 == 0:\n",
    "            local_acc.append(evaluate(model, test_loader, device))\n",
    "\n",
    "    # EPOCHS=1\n",
    "    # LR=0.001\n",
    "    # R=-1\n",
    "    common_data = []\n",
    "    avg_logits = []\n",
    "    entropies = []\n",
    "    \n",
    "    server_model.train()    \n",
    "    for model in local_models:\n",
    "        model.eval()\n",
    "\n",
    "    cor = 0\n",
    "    tot = 0\n",
    "    for x, y in common_loader:\n",
    "        #for _ in range(common_data_size):\n",
    "            #x = torch.randn(batch_size, 1, 28, 28, device=device)\n",
    "            x = x.to(device)\n",
    "            common_data.append(x)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                local_logits = [m(x).detach() for m in local_models]\n",
    "                stacked = torch.stack(local_logits)\n",
    "                probs = F.softmax(stacked, dim=-1) \n",
    "                SEL=(torch.max(probs,-1)[0]<targetProb)\n",
    "                P = probs+0.0\n",
    "                P[SEL] *=0\n",
    "                P = torch.sum(P,axis=0)\n",
    "                S=torch.sum(P,1)\n",
    "                SEL = S>0\n",
    "                P = P[SEL] * (1/(S[SEL])).view([-1,1])\n",
    "                Pmax.append(torch.max(P,1)[0].data.cpu())\n",
    "            if torch.sum(SEL)>0:\n",
    "                pred = P.argmax(dim=1, keepdim=True)\n",
    "    \n",
    "                server_optimizer.zero_grad()\n",
    "\n",
    "                \n",
    "                # log_prob = F.log_softmax(server_model(x[SEL]), dim=-1)\n",
    "                # loss = criterion(log_prob, P )\n",
    "\n",
    "                output = server_model(x[SEL])\n",
    "                loss = criterionCE(output, pred.squeeze())\n",
    "                \n",
    "                loss.backward()\n",
    "                server_optimizer.step()\n",
    "                pred = pred.cpu()\n",
    "                cor += pred.eq(y[SEL.cpu()].view_as(pred)).sum().item()\n",
    "                tot += len(y[SEL.cpu()])\n",
    "\n",
    "    targetProb *= up\n",
    "    if targetProb > 0.9:\n",
    "        targetProb = 0.9\n",
    "\n",
    "    \n",
    "    acc = evaluate(server_model, test_loader, device)\n",
    "    print(f\"{r + 1}: {cor/tot*100}% Server model accuracy on test set: {acc*100:.2f}%, local models average accuracy before copying: {np.mean(local_acc)*100:.2f}%\")\n",
    "    for model in local_models:\n",
    "        model.load_state_dict(server_model.state_dict())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165c6d09-5617-4d50-ad6c-b47e1bd4793a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03571547-c81f-46a2-a720-d55609200a9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295deb7b-4045-4454-9c71-2a76cc86759c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfeef4e0-c9fe-4d4d-ab02-5fc2cbd7014b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4298aeca-f0e5-420f-adb2-720c0827413b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "id": "e90687e5-7388-482a-b307-22fc08cf273a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: 83.63889533534463% Server model accuracy on test set: 82.30%, local models average accuracy before copying: 84.05%\n",
      "2: 83.38148618976078% Server model accuracy on test set: 82.20%, local models average accuracy before copying: 83.10%\n",
      "3: 83.7571780147662% Server model accuracy on test set: 82.40%, local models average accuracy before copying: 82.80%\n",
      "4: 83.45724907063197% Server model accuracy on test set: 83.40%, local models average accuracy before copying: 83.35%\n",
      "47: 83.9041496201052% Server model accuracy on test set: 81.00%, local models average accuracy before copying: 81.80%\n",
      "48: 83.91436593355171% Server model accuracy on test set: 81.40%, local models average accuracy before copying: 81.75%\n",
      "49: 84.22279189000234% Server model accuracy on test set: 81.90%, local models average accuracy before copying: 82.15%\n",
      "50: 84.11149825783973% Server model accuracy on test set: 82.00%, local models average accuracy before copying: 82.40%\n",
      "51: 84.09459772779968% Server model accuracy on test set: 83.50%, local models average accuracy before copying: 82.40%\n",
      "52: 84.34184446776261% Server model accuracy on test set: 83.10%, local models average accuracy before copying: 83.45%\n",
      "53: 84.18283843815759% Server model accuracy on test set: 82.10%, local models average accuracy before copying: 83.05%\n",
      "54: 84.90521606028494% Server model accuracy on test set: 82.20%, local models average accuracy before copying: 82.65%\n",
      "55: 85.29860377801243% Server model accuracy on test set: 83.50%, local models average accuracy before copying: 83.00%\n",
      "56: 85.10142224294708% Server model accuracy on test set: 82.00%, local models average accuracy before copying: 83.60%\n",
      "57: 84.31326709526593% Server model accuracy on test set: 82.40%, local models average accuracy before copying: 82.95%\n",
      "58: 85.49216740706103% Server model accuracy on test set: 82.60%, local models average accuracy before copying: 82.85%\n",
      "59: 85.52004648460198% Server model accuracy on test set: 83.70%, local models average accuracy before copying: 83.25%\n",
      "60: 85.84994138335287% Server model accuracy on test set: 84.60%, local models average accuracy before copying: 84.10%\n",
      "61: 85.8611825192802% Server model accuracy on test set: 84.70%, local models average accuracy before copying: 84.95%\n",
      "62: 85.83690987124464% Server model accuracy on test set: 85.10%, local models average accuracy before copying: 84.85%\n",
      "63: 86.10177350179669% Server model accuracy on test set: 85.10%, local models average accuracy before copying: 85.10%\n",
      "64: 86.26444159178433% Server model accuracy on test set: 84.40%, local models average accuracy before copying: 85.50%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[475], line 52\u001b[0m\n\u001b[1;32m     49\u001b[0m output \u001b[38;5;241m=\u001b[39m server_model(x[SEL])\n\u001b[1;32m     50\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterionCE(output, pred\u001b[38;5;241m.\u001b[39msqueeze())\n\u001b[0;32m---> 52\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m server_optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     54\u001b[0m pred \u001b[38;5;241m=\u001b[39m pred\u001b[38;5;241m.\u001b[39mcpu()\n",
      "File \u001b[0;32m~/.conda/envs/fair-chem/lib/python3.11/site-packages/torch/_tensor.py:647\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    637\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    638\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    639\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    640\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    645\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    646\u001b[0m     )\n\u001b[0;32m--> 647\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    648\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    649\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/fair-chem/lib/python3.11/site-packages/torch/autograd/__init__.py:354\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    349\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    351\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    353\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 354\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    356\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    357\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    359\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_tuple\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    360\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    361\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    362\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/fair-chem/lib/python3.11/site-packages/torch/autograd/graph.py:829\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    827\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    828\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 829\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    830\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    831\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    833\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for r in range(100):\n",
    "    Pmax=[]\n",
    "    local_acc = []\n",
    "    for i, (model, loader, opt) in enumerate(zip(local_models, client_loaders, local_optimizers)):\n",
    "        train_local(model, loader, opt, device, epochs=EPOCHS, r=R, lr=LR)\n",
    "        if i % 5 == 0:\n",
    "            local_acc.append(evaluate(model, test_loader, device))\n",
    "\n",
    "    EPOCHS=1\n",
    "    # LR=0.001\n",
    "    # R=-1\n",
    "    common_data = []\n",
    "    avg_logits = []\n",
    "    entropies = []\n",
    "    \n",
    "    server_model.train()    \n",
    "    for model in local_models:\n",
    "        model.eval()\n",
    "\n",
    "    cor = 0\n",
    "    tot = 0\n",
    "    for x, y in common_loader:\n",
    "        #for _ in range(common_data_size):\n",
    "            #x = torch.randn(batch_size, 1, 28, 28, device=device)\n",
    "            x = x.to(device)\n",
    "            common_data.append(x)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                local_logits = [m(x).detach() for m in local_models]\n",
    "                stacked = torch.stack(local_logits)\n",
    "                probs = F.softmax(stacked, dim=-1) \n",
    "                SEL=(torch.max(probs,-1)[0]<targetProb)\n",
    "                P = probs+0.0\n",
    "                P[SEL] *=0\n",
    "                P = torch.sum(P,axis=0)\n",
    "                S=torch.sum(P,1)\n",
    "                SEL = S>0\n",
    "                P = P[SEL] * (1/(S[SEL])).view([-1,1])\n",
    "                Pmax.append(torch.max(P,1)[0].data.cpu())\n",
    "            if torch.sum(SEL)>0:\n",
    "                pred = P.argmax(dim=1, keepdim=True)\n",
    "    \n",
    "                server_optimizer.zero_grad()\n",
    "\n",
    "                \n",
    "                # log_prob = F.log_softmax(server_model(x[SEL]), dim=-1)\n",
    "                # loss = criterion(log_prob, P )\n",
    "\n",
    "                output = server_model(x[SEL])\n",
    "                loss = criterionCE(output, pred.squeeze())\n",
    "                \n",
    "                loss.backward()\n",
    "                server_optimizer.step()\n",
    "                pred = pred.cpu()\n",
    "                cor += pred.eq(y[SEL.cpu()].view_as(pred)).sum().item()\n",
    "                tot += len(y[SEL.cpu()])\n",
    "\n",
    "    targetProb *= up\n",
    "    if targetProb > 0.9:\n",
    "        targetProb = 0.9\n",
    "\n",
    "    \n",
    "    acc = evaluate(server_model, test_loader, device)\n",
    "    print(f\"{r + 1}: {cor/tot*100}% Server model accuracy on test set: {acc*100:.2f}%, local models average accuracy before copying: {np.mean(local_acc)*100:.2f}%\")\n",
    "    for model in local_models:\n",
    "        model.load_state_dict(server_model.state_dict())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "id": "7a5dac4c-b0ee-4eb4-8f41-2a87e1956f91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.3201, device='cuda:0', grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 467,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterionCE(output, pred.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "id": "286c6dcf-1ec5-4a06-a171-c6183d0b5cb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(torch.cat(Pmax));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e67ace3-e916-4126-b476-6610d01823ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "id": "c0d9b7a0-23e4-48ee-b7de-9e11e8587d1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy centralized 0.911\n",
      "accuracy centralized 0.955\n",
      "accuracy centralized 0.961\n",
      "accuracy centralized 0.963\n",
      "accuracy centralized 0.969\n",
      "accuracy centralized 0.955\n",
      "accuracy centralized 0.963\n",
      "accuracy centralized 0.973\n",
      "accuracy centralized 0.97\n",
      "accuracy centralized 0.974\n"
     ]
    }
   ],
   "source": [
    "centralized = SimpleCNN().to(device)\n",
    "\n",
    "centralized_optimizer = optim.Adam(centralized.parameters(), lr=0.01)\n",
    "model.train()\n",
    "criterion = nn.CrossEntropyLoss()    \n",
    "\n",
    "for _ in range(10):\n",
    "    for j, (data, target) in enumerate(common_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        centralized_optimizer.zero_grad()\n",
    "        output = centralized(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        centralized_optimizer.step()\n",
    "    acc = evaluate(centralized, test_loader, device)\n",
    "    print(\"accuracy centralized\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "eeac16d9-ad18-4a9f-8576-407795a0d8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b8d800-0414-4650-9804-324e1cac0dca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b9b4b4-e039-4c67-90df-fccea6feec0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "78808d83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.068"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "68be3763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.068\n",
      "0.068\n",
      "0.068\n",
      "0.068\n",
      "0.068\n",
      "0.068\n",
      "0.068\n",
      "0.068\n",
      "0.068\n",
      "0.068\n"
     ]
    }
   ],
   "source": [
    "for model in local_models:\n",
    "    model.load_state_dict(server_model.state_dict())\n",
    "    acc = evaluate(model, test_loader, device)\n",
    "    print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "becd6cdb-333d-4ab1-85fc-ae163647a387",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_local(model, common_loader, opt, device, epochs=1, r=-1, lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "735afc92-abc5-429f-9df5-6c3ea2c55700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.935\n"
     ]
    }
   ],
   "source": [
    "acc = evaluate(model, test_loader, device)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "dc12cde4-3c69-4a3f-8904-e79e1a6dc48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_local(model, client_loaders[-1], opt, device, epochs=1, r=-1, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "684fab1a-4227-49dd-8d39-5556dd4518dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.687\n"
     ]
    }
   ],
   "source": [
    "acc = evaluate(model, test_loader, device)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6635442a-1568-4c6a-98fb-38a164ef5f69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddddab1a-2520-4df4-bcee-241105ed89d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
