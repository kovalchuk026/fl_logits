{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "43b405cc-a8d3-456e-84bc-3a995aa95f45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f593c86e-b59e-417d-aa31-0415aa6a8fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi | grep 300W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "15f79735-c659-4631-9c89-d560a3ba2b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "# pathPrefix =\"../data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1261199a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8fce3d20-015e-4918-a96a-21c0c2b8c0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "329d0e2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fe4601b5190>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = 0\n",
    "device = torch.device(\"cuda:4\" if torch.cuda.is_available() else \"cpu\")\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9e726299",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class SimpleCNN(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "#         self.conv1 = nn.Conv2d(1, 16, 3, padding=1)\n",
    "#         self.fc = nn.Linear(16 * 28 * 28, 10)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = torch.relu(self.conv1(x))\n",
    "#         x = x.view(-1, 16 * 28 * 28)\n",
    "#         return self.fc(x)\n",
    "\n",
    "# from https://medium.com/@deepeshdeepakdd2/lenet-5-implementation-on-mnist-in-pytorch-c6f2ee306e37\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.feature = nn.Sequential(\n",
    "            #1\n",
    "            nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, stride=1, padding=2),   # 28*28->32*32-->28*28\n",
    "            nn.Tanh(),\n",
    "            nn.AvgPool2d(kernel_size=2, stride=2),  # 14*14\n",
    "            \n",
    "            #2\n",
    "            nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1),  # 10*10\n",
    "            nn.Tanh(),\n",
    "            nn.AvgPool2d(kernel_size=2, stride=2),  # 5*5\n",
    "            \n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=16*5*5, out_features=120),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(in_features=120, out_features=84),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(in_features=84, out_features=10),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.classifier(self.feature(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "872b1466",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_fixed_class_client_loaders(num_clients=4, k=5, batch_size=32):  #checked\n",
    "    \n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ])\n",
    "\n",
    "    dataset = datasets.MNIST(root=\"./data\", train=True, download=True, transform=transform)\n",
    "\n",
    "    # Build class indices\n",
    "    class_indices = defaultdict(list)\n",
    "    for idx, (_, label) in enumerate(dataset):\n",
    "        class_indices[label].append(idx)\n",
    "    \n",
    "    for c in class_indices:\n",
    "        np.random.shuffle(class_indices[c])\n",
    "\n",
    "    # Assign exactly k unique classes to each client\n",
    "    all_classes = np.arange(10)\n",
    "    client_classes = [np.random.choice(all_classes, size=k, replace=False) for _ in range(num_clients)]\n",
    "\n",
    "    client_indices = [[] for _ in range(num_clients)]\n",
    "\n",
    "    # Distribute samples of each class to clients that need it\n",
    "    for class_id in range(10):\n",
    "    \n",
    "        # Clients that selected this class\n",
    "        clients_with_class = [cid for cid, classes in enumerate(client_classes) if class_id in classes]\n",
    "        if not clients_with_class:\n",
    "            continue\n",
    "\n",
    "        # Split class data among those clients\n",
    "        splits = np.array_split(class_indices[class_id], len(clients_with_class))\n",
    "        for cid, split in zip(clients_with_class, splits):\n",
    "            client_indices[cid].extend(split.tolist())\n",
    "\n",
    "    client_loaders = []\n",
    "    for indices in client_indices:\n",
    "        if not indices:\n",
    "            indices = [0] \n",
    "        loader = DataLoader(\n",
    "            Subset(dataset, indices),\n",
    "            batch_size=batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=2,\n",
    "            pin_memory=True,\n",
    "            drop_last=True\n",
    "        )\n",
    "        client_loaders.append(loader)\n",
    "    return client_loaders, client_classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5e42f238",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_local(model, loader, optimizer, device, epochs=1, r=-1, lr = 0.01): #checked\n",
    "    model.train()\n",
    "    criterion = nn.CrossEntropyLoss()    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    for _ in range(epochs):\n",
    "        for j, (data, target) in enumerate(loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if r>=0:\n",
    "                if j>=r:\n",
    "                    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "352fa6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_server(server_model, avg_logits, common_data, optimizer, epochs=1): #checked\n",
    "    server_model.train()\n",
    "    criterion = nn.KLDivLoss(reduction=\"batchmean\")\n",
    "\n",
    "    for _ in range(epochs):\n",
    "        for x, y in zip(common_data, avg_logits):\n",
    "            optimizer.zero_grad()\n",
    "            log_prob = F.log_softmax(server_model(x), dim=-1)\n",
    "            loss = criterion(log_prob, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f57793ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_loader, device, classes=None): #checked\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            mask = [1] * len(data)\n",
    "            if classes is not None:\n",
    "                mask = np.isin(target, classes)\n",
    "            data, target = data[mask].to(device), target[mask].to(device)\n",
    "            output = model(data)\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "            total += target.size(0)\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "88c50ccb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False,  True, False,  True,  True])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = np.array([1, 2, 3, 4, 5])\n",
    "classes = np.array([0, 2 ,4 ,5, 7])\n",
    "np.isin(target, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "77d95ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_out_uncertain_logits(logits_list, threshold=1.2):  #checked\n",
    "    stacked = torch.stack(logits_list)        # [M, B, C]\n",
    "    # Compute entropy per model per sample\n",
    "    probs = F.softmax(stacked, dim=-1)        # [M, B, C]\n",
    "    entropy = -(probs * probs.log()).sum(dim=-1)   # [M, B]\n",
    "\n",
    "    # Mask: True if confident\n",
    "    mask = (entropy < threshold).float()      # [M, B]\n",
    "\n",
    "    # Expand mask to logits shape\n",
    "    mask_expanded = mask.unsqueeze(-1)        # [M, B, 1]\n",
    "\n",
    "    # Zero out uncertain logits\n",
    "    masked_logits = stacked * mask_expanded   # [M, B, C]\n",
    "\n",
    "    # Count how many models contributed per sample\n",
    "    denom = mask.sum(dim=0).unsqueeze(-1).clamp(min=1)  # [B, 1]\n",
    "\n",
    "    # Average only over confident models\n",
    "    avg_logits = masked_logits.sum(dim=0) / denom       # [B, C]\n",
    "\n",
    "    masked_probs = probs * mask_expanded\n",
    "    avg_probs = masked_probs.sum(dim=0) / denom\n",
    "    return avg_probs, torch.mean(entropy)\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e211dd6b-73fa-43cf-a991-6ff2e327e5ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd874ab-7511-4519-88f5-5fb2d5aff2b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b8c207-7f61-4e9d-ba33-468895d52de6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c5be6a-9368-4b01-bc3a-7e00398aeeb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a9e046-1438-48a4-b0cc-803b4946d118",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "31c71257",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_clients = 20\n",
    "batch_size = 64\n",
    "common_data_size = 512\n",
    "k = 7\n",
    "threshold = 3\n",
    "\n",
    "client_loaders, client_classes = create_fixed_class_client_loaders(num_clients, batch_size=batch_size, k=k)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# Create a subset with specific indices\n",
    "indices = list(range(len(test_dataset)))  # e.g., first 1000 samples\n",
    "np.random.shuffle(indices)\n",
    "testSubset = Subset(test_dataset, indices[:1000])\n",
    "commonSubset = Subset(test_dataset, indices[1000:])\n",
    "\n",
    "# Use with DataLoader\n",
    "test_loader = torch.utils.data.DataLoader(testSubset, batch_size=batch_size, shuffle=False)\n",
    "common_loader = torch.utils.data.DataLoader(commonSubset, batch_size=batch_size, shuffle=True,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "263adb94-6a97-4dbd-9a2a-760a73990eb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "YS=[]\n",
    "for loader in client_loaders:\n",
    "    Y=[]\n",
    "    for x,y in loader:\n",
    "        Y.append(y)\n",
    "    YS.append(torch.cat(Y))\n",
    "Ys = torch.cat(YS)\n",
    "plt.hist(Ys,10);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e74967c8-0589-47e9-b7a7-89202308adda",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_models = [SimpleCNN().to(device) for _ in range(num_clients)]\n",
    "server_model = SimpleCNN().to(device)\n",
    "\n",
    "local_optimizers = [optim.Adam(m.parameters(), lr=0.01) for m in local_models]\n",
    "server_optimizer = optim.Adam(server_model.parameters(), lr=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b95b8d49-474d-4f5b-9c75-acf62b85ff87",
   "metadata": {},
   "outputs": [],
   "source": [
    "R=-1\n",
    "LR=0.01\n",
    "EPOCHS = 20\n",
    "criterion = nn.KLDivLoss(reduction=\"batchmean\")\n",
    "up = 1.1\n",
    "targetProb = 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "16ef8c80-90b5-478d-9b7b-18095f4135a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterionCE = nn.CrossEntropyLoss()    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2068c674",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: 97.56666666666666% Server model accuracy on test set: 93.60%, local models average accuracy before copying: 96.33%\n"
     ]
    }
   ],
   "source": [
    "for r in range(2):\n",
    "    Pmax=[]\n",
    "    local_acc = []\n",
    "    for i, (model, loader, opt) in enumerate(zip(local_models, client_loaders, local_optimizers)):\n",
    "        train_local(model, loader, opt, device, epochs=EPOCHS, r=R, lr=LR)\n",
    "        if i % 5 == 0:\n",
    "            local_acc.append(evaluate(model, test_loader, device, client_classes[i]))\n",
    "\n",
    "    # EPOCHS=1\n",
    "    # LR=0.001\n",
    "    # R=-1\n",
    "    common_data = []\n",
    "    avg_logits = []\n",
    "    entropies = []\n",
    "    \n",
    "    server_model.train()    \n",
    "    for model in local_models:\n",
    "        model.eval()\n",
    "\n",
    "    cor = 0\n",
    "    tot = 0\n",
    "    for x, y in common_loader:\n",
    "        #for _ in range(common_data_size):\n",
    "            #x = torch.randn(batch_size, 1, 28, 28, device=device)\n",
    "            x = x.to(device)\n",
    "            common_data.append(x)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                local_logits = [m(x).detach() for m in local_models]\n",
    "                stacked = torch.stack(local_logits)\n",
    "                probs = F.softmax(stacked, dim=-1) \n",
    "                SEL=(torch.max(probs,-1)[0]<targetProb)\n",
    "                P = probs+0.0\n",
    "                P[SEL] *=0\n",
    "                P = torch.sum(P,axis=0)\n",
    "                S=torch.sum(P,1)\n",
    "                SEL = S>0\n",
    "                P = P[SEL] * (1/(S[SEL])).view([-1,1])\n",
    "                Pmax.append(torch.max(P,1)[0].data.cpu())\n",
    "            if torch.sum(SEL)>0:\n",
    "                pred = P.argmax(dim=1, keepdim=True)\n",
    "    \n",
    "                server_optimizer.zero_grad()\n",
    "\n",
    "                \n",
    "                # log_prob = F.log_softmax(server_model(x[SEL]), dim=-1)\n",
    "                # loss = criterion(log_prob, P )\n",
    "\n",
    "                output = server_model(x[SEL])\n",
    "                loss = criterionCE(output, pred.squeeze())\n",
    "                \n",
    "                loss.backward()\n",
    "                server_optimizer.step()\n",
    "                pred = pred.cpu()\n",
    "                cor += pred.eq(y[SEL.cpu()].view_as(pred)).sum().item()\n",
    "                tot += len(y[SEL.cpu()])\n",
    "\n",
    "    targetProb *= up\n",
    "    if targetProb > 0.9:\n",
    "        targetProb = 0.9\n",
    "\n",
    "    \n",
    "    acc = evaluate(server_model, test_loader, device)\n",
    "    print(f\"{r + 1}: {cor/tot*100}% Server model accuracy on test set: {acc*100:.2f}%, local models average accuracy before copying: {np.mean(local_acc)*100:.2f}%\")\n",
    "    for model in local_models:\n",
    "        model.load_state_dict(server_model.state_dict())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165c6d09-5617-4d50-ad6c-b47e1bd4793a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03571547-c81f-46a2-a720-d55609200a9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295deb7b-4045-4454-9c71-2a76cc86759c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfeef4e0-c9fe-4d4d-ab02-5fc2cbd7014b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4298aeca-f0e5-420f-adb2-720c0827413b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90687e5-7388-482a-b307-22fc08cf273a",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[38]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m local_acc = []\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, (model, loader, opt) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mzip\u001b[39m(local_models, client_loaders, local_optimizers)):\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m     \u001b[43mtrain_local\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mLR\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m i % \u001b[32m5\u001b[39m == \u001b[32m0\u001b[39m:\n\u001b[32m      7\u001b[39m         local_acc.append(evaluate(model, test_loader, device))\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 11\u001b[39m, in \u001b[36mtrain_local\u001b[39m\u001b[34m(model, loader, optimizer, device, epochs, r, lr)\u001b[39m\n\u001b[32m      9\u001b[39m output = model(data)\n\u001b[32m     10\u001b[39m loss = criterion(output, target)\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m optimizer.step()\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m r>=\u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/fl_logits/myenv/lib/python3.12/site-packages/torch/_tensor.py:647\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    637\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    638\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    639\u001b[39m         Tensor.backward,\n\u001b[32m    640\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    645\u001b[39m         inputs=inputs,\n\u001b[32m    646\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m647\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    648\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    649\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/fl_logits/myenv/lib/python3.12/site-packages/torch/autograd/__init__.py:354\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    349\u001b[39m     retain_graph = create_graph\n\u001b[32m    351\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    352\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    353\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m354\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_tuple\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    362\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/fl_logits/myenv/lib/python3.12/site-packages/torch/autograd/graph.py:829\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    827\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    828\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m829\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    830\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    831\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    832\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    833\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "for r in range(100):\n",
    "    Pmax=[]\n",
    "    local_acc = []\n",
    "    for i, (model, loader, opt) in enumerate(zip(local_models, client_loaders, local_optimizers)):\n",
    "        train_local(model, loader, opt, device, epochs=EPOCHS, r=R, lr=LR)\n",
    "        if i % 5 == 0:\n",
    "            local_acc.append(evaluate(model, test_loader, device))\n",
    "\n",
    "    EPOCHS=1\n",
    "    # LR=0.001\n",
    "    # R=-1\n",
    "    common_data = []\n",
    "    avg_logits = []\n",
    "    entropies = []\n",
    "    \n",
    "    server_model.train()    \n",
    "    for model in local_models:\n",
    "        model.eval()\n",
    "\n",
    "    cor = 0\n",
    "    tot = 0\n",
    "    for x, y in common_loader:\n",
    "        #for _ in range(common_data_size):\n",
    "            #x = torch.randn(batch_size, 1, 28, 28, device=device)\n",
    "            x = x.to(device)\n",
    "            common_data.append(x)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                local_logits = [m(x).detach() for m in local_models]\n",
    "                stacked = torch.stack(local_logits)\n",
    "                probs = F.softmax(stacked, dim=-1) \n",
    "                SEL=(torch.max(probs,-1)[0]<targetProb)\n",
    "                P = probs+0.0\n",
    "                P[SEL] *=0\n",
    "                P = torch.sum(P,axis=0)\n",
    "                S=torch.sum(P,1)\n",
    "                SEL = S>0\n",
    "                P = P[SEL] * (1/(S[SEL])).view([-1,1])\n",
    "                Pmax.append(torch.max(P,1)[0].data.cpu())\n",
    "            if torch.sum(SEL)>0:\n",
    "                pred = P.argmax(dim=1, keepdim=True)\n",
    "    \n",
    "                server_optimizer.zero_grad()\n",
    "\n",
    "                \n",
    "                # log_prob = F.log_softmax(server_model(x[SEL]), dim=-1)\n",
    "                # loss = criterion(log_prob, P )\n",
    "\n",
    "                output = server_model(x[SEL])\n",
    "                loss = criterionCE(output, pred.squeeze())\n",
    "                \n",
    "                loss.backward()\n",
    "                server_optimizer.step()\n",
    "                pred = pred.cpu()\n",
    "                cor += pred.eq(y[SEL.cpu()].view_as(pred)).sum().item()\n",
    "                tot += len(y[SEL.cpu()])\n",
    "\n",
    "    targetProb *= up\n",
    "    if targetProb > 0.9:\n",
    "        targetProb = 0.9\n",
    "\n",
    "    \n",
    "    acc = evaluate(server_model, test_loader, device)\n",
    "    print(f\"{r + 1}: {cor/tot*100}% Server model accuracy on test set: {acc*100:.2f}%, local models average accuracy before copying: {np.mean(local_acc)*100:.2f}%\")\n",
    "    for model in local_models:\n",
    "        model.load_state_dict(server_model.state_dict())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5dac4c-b0ee-4eb4-8f41-2a87e1956f91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.3201, device='cuda:0', grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 467,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterionCE(output, pred.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286c6dcf-1ec5-4a06-a171-c6183d0b5cb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(torch.cat(Pmax));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e67ace3-e916-4126-b476-6610d01823ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d9b7a0-23e4-48ee-b7de-9e11e8587d1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy centralized 0.911\n",
      "accuracy centralized 0.955\n",
      "accuracy centralized 0.961\n",
      "accuracy centralized 0.963\n",
      "accuracy centralized 0.969\n",
      "accuracy centralized 0.955\n",
      "accuracy centralized 0.963\n",
      "accuracy centralized 0.973\n",
      "accuracy centralized 0.97\n",
      "accuracy centralized 0.974\n"
     ]
    }
   ],
   "source": [
    "centralized = SimpleCNN().to(device)\n",
    "\n",
    "centralized_optimizer = optim.Adam(centralized.parameters(), lr=0.01)\n",
    "model.train()\n",
    "criterion = nn.CrossEntropyLoss()    \n",
    "\n",
    "for _ in range(10):\n",
    "    for j, (data, target) in enumerate(common_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        centralized_optimizer.zero_grad()\n",
    "        output = centralized(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        centralized_optimizer.step()\n",
    "    acc = evaluate(centralized, test_loader, device)\n",
    "    print(\"accuracy centralized\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeac16d9-ad18-4a9f-8576-407795a0d8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b8d800-0414-4650-9804-324e1cac0dca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b9b4b4-e039-4c67-90df-fccea6feec0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78808d83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.068"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68be3763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.068\n",
      "0.068\n",
      "0.068\n",
      "0.068\n",
      "0.068\n",
      "0.068\n",
      "0.068\n",
      "0.068\n",
      "0.068\n",
      "0.068\n"
     ]
    }
   ],
   "source": [
    "for model in local_models:\n",
    "    model.load_state_dict(server_model.state_dict())\n",
    "    acc = evaluate(model, test_loader, device)\n",
    "    print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "becd6cdb-333d-4ab1-85fc-ae163647a387",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_local(model, common_loader, opt, device, epochs=1, r=-1, lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735afc92-abc5-429f-9df5-6c3ea2c55700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.935\n"
     ]
    }
   ],
   "source": [
    "acc = evaluate(model, test_loader, device)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc12cde4-3c69-4a3f-8904-e79e1a6dc48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_local(model, client_loaders[-1], opt, device, epochs=1, r=-1, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684fab1a-4227-49dd-8d39-5556dd4518dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.687\n"
     ]
    }
   ],
   "source": [
    "acc = evaluate(model, test_loader, device)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6635442a-1568-4c6a-98fb-38a164ef5f69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddddab1a-2520-4df4-bcee-241105ed89d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv (3.12.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
