{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43b405cc-a8d3-456e-84bc-3a995aa95f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f593c86e-b59e-417d-aa31-0415aa6a8fcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| 30%   44C    P2              80W / 300W |   1297MiB / 49140MiB |      5%      Default |\n",
      "| 30%   31C    P8              28W / 300W |  13253MiB / 49140MiB |      0%      Default |\n",
      "| 30%   31C    P8              23W / 300W |     12MiB / 49140MiB |      0%      Default |\n",
      "| 30%   31C    P8              17W / 300W |  22353MiB / 49140MiB |      0%      Default |\n",
      "| 50%   75C    P2             292W / 300W |  35619MiB / 49140MiB |     96%      Default |\n",
      "| 42%   71C    P2             257W / 300W |   6769MiB / 49140MiB |    100%      Default |\n",
      "| 30%   45C    P2              88W / 300W |   4958MiB / 49140MiB |     27%      Default |\n",
      "| 30%   49C    P2              99W / 300W |   6060MiB / 49140MiB |     34%      Default |\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi | grep 300W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15f79735-c659-4631-9c89-d560a3ba2b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "pathPrefix =\"../data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1261199a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8fce3d20-015e-4918-a96a-21c0c2b8c0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "329d0e2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7d04bdb5e410>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = 0\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "9e726299",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class SimpleCNN(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "#         self.conv1 = nn.Conv2d(1, 16, 3, padding=1)\n",
    "#         self.fc = nn.Linear(16 * 28 * 28, 10)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = torch.relu(self.conv1(x))\n",
    "#         x = x.view(-1, 16 * 28 * 28)\n",
    "#         return self.fc(x)\n",
    "\n",
    "# from https://medium.com/@deepeshdeepakdd2/lenet-5-implementation-on-mnist-in-pytorch-c6f2ee306e37\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.feature = nn.Sequential(\n",
    "            #1\n",
    "            nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, stride=1, padding=2),   # 28*28->32*32-->28*28\n",
    "            nn.Tanh(),\n",
    "            nn.AvgPool2d(kernel_size=2, stride=2),  # 14*14\n",
    "            \n",
    "            #2\n",
    "            nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1),  # 10*10\n",
    "            nn.Tanh(),\n",
    "            nn.AvgPool2d(kernel_size=2, stride=2),  # 5*5\n",
    "            \n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=16*5*5, out_features=120),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(in_features=120, out_features=84),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(in_features=84, out_features=10),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.classifier(self.feature(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "872b1466",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_fixed_class_client_loaders(num_clients=4, k=5, batch_size=32):  #checked\n",
    "    \n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ])\n",
    "\n",
    "    dataset = datasets.MNIST(root=\"./data\", train=True, download=True, transform=transform)\n",
    "\n",
    "    # Build class indices\n",
    "    class_indices = defaultdict(list)\n",
    "    for idx, (_, label) in enumerate(dataset):\n",
    "        class_indices[label].append(idx)\n",
    "    \n",
    "    for c in class_indices:\n",
    "        np.random.shuffle(class_indices[c])\n",
    "\n",
    "    # Assign exactly k unique classes to each client\n",
    "    all_classes = np.arange(10)\n",
    "    client_classes = [np.random.choice(all_classes, size=k, replace=False) for _ in range(num_clients)]\n",
    "\n",
    "    client_indices = [[] for _ in range(num_clients)]\n",
    "\n",
    "    # Distribute samples of each class to clients that need it\n",
    "    for class_id in range(10):\n",
    "    \n",
    "        # Clients that selected this class\n",
    "        clients_with_class = [cid for cid, classes in enumerate(client_classes) if class_id in classes]\n",
    "        if not clients_with_class:\n",
    "            continue\n",
    "\n",
    "        # Split class data among those clients\n",
    "        splits = np.array_split(class_indices[class_id], len(clients_with_class))\n",
    "        for cid, split in zip(clients_with_class, splits):\n",
    "            client_indices[cid].extend(split.tolist())\n",
    "\n",
    "    client_loaders = []\n",
    "    for indices in client_indices:\n",
    "        if not indices:\n",
    "            indices = [0] \n",
    "        loader = DataLoader(\n",
    "            Subset(dataset, indices),\n",
    "            batch_size=batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=2,\n",
    "            pin_memory=True,\n",
    "            drop_last=True\n",
    "        )\n",
    "        client_loaders.append(loader)\n",
    "    return client_loaders, client_classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "id": "5e42f238",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_local(model, loader, optimizer, device, epochs=1, r=-1, lr = 0.01): #checked\n",
    "    model.train()\n",
    "    criterion = nn.CrossEntropyLoss()    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    for _ in range(epochs):\n",
    "        for j, (data, target) in enumerate(loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if r>=0:\n",
    "                if j>=r:\n",
    "                    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "352fa6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_server(server_model, avg_logits, common_data, optimizer, epochs=1): #checked\n",
    "    server_model.train()\n",
    "    criterion = nn.KLDivLoss(reduction=\"batchmean\")\n",
    "\n",
    "    for _ in range(epochs):\n",
    "        for x, y in zip(common_data, avg_logits):\n",
    "            optimizer.zero_grad()\n",
    "            log_prob = F.log_softmax(server_model(x), dim=-1)\n",
    "            loss = criterion(log_prob, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "f57793ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_loader, device): #checked\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "            total += target.size(0)\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "77d95ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_out_uncertain_logits(logits_list, threshold=1.2):  #checked\n",
    "    stacked = torch.stack(logits_list)        # [M, B, C]\n",
    "    # Compute entropy per model per sample\n",
    "    probs = F.softmax(stacked, dim=-1)        # [M, B, C]\n",
    "    entropy = -(probs * probs.log()).sum(dim=-1)   # [M, B]\n",
    "\n",
    "    # Mask: True if confident\n",
    "    mask = (entropy < threshold).float()      # [M, B]\n",
    "\n",
    "    # Expand mask to logits shape\n",
    "    mask_expanded = mask.unsqueeze(-1)        # [M, B, 1]\n",
    "\n",
    "    # Zero out uncertain logits\n",
    "    masked_logits = stacked * mask_expanded   # [M, B, C]\n",
    "\n",
    "    # Count how many models contributed per sample\n",
    "    denom = mask.sum(dim=0).unsqueeze(-1).clamp(min=1)  # [B, 1]\n",
    "\n",
    "    # Average only over confident models\n",
    "    avg_logits = masked_logits.sum(dim=0) / denom       # [B, C]\n",
    "\n",
    "    masked_probs = probs * mask_expanded\n",
    "    avg_probs = masked_probs.sum(dim=0) / denom\n",
    "    return avg_probs, torch.mean(entropy)\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "e211dd6b-73fa-43cf-a991-6ff2e327e5ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "ddd874ab-7511-4519-88f5-5fb2d5aff2b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b8c207-7f61-4e9d-ba33-468895d52de6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "b5c5be6a-9368-4b01-bc3a-7e00398aeeb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a9e046-1438-48a4-b0cc-803b4946d118",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "id": "31c71257",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_clients = 10\n",
    "batch_size = 64\n",
    "common_data_size = 512\n",
    "k = 7\n",
    "threshold = 3\n",
    "\n",
    "client_loaders, _ = create_fixed_class_client_loaders(num_clients, batch_size=batch_size, k=k)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# Create a subset with specific indices\n",
    "indices = list(range(len(test_dataset)))  # e.g., first 1000 samples\n",
    "np.random.shuffle(indices)\n",
    "testSubset = Subset(test_dataset, indices[:1000])\n",
    "commonSubset = Subset(test_dataset, indices[1000:])\n",
    "\n",
    "# Use with DataLoader\n",
    "test_loader = torch.utils.data.DataLoader(testSubset, batch_size=batch_size, shuffle=False)\n",
    "common_loader = torch.utils.data.DataLoader(commonSubset, batch_size=batch_size, shuffle=True,)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "id": "263adb94-6a97-4dbd-9a2a-760a73990eb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "YS=[]\n",
    "for loader in client_loaders:\n",
    "    Y=[]\n",
    "    for x,y in loader:\n",
    "        Y.append(y)\n",
    "    YS.append(torch.cat(Y))\n",
    "Ys = torch.cat(YS)\n",
    "plt.hist(Ys,10);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "id": "e74967c8-0589-47e9-b7a7-89202308adda",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_models = [SimpleCNN().to(device) for _ in range(num_clients)]\n",
    "server_model = SimpleCNN().to(device)\n",
    "\n",
    "local_optimizers = [optim.Adam(m.parameters(), lr=0.01) for m in local_models]\n",
    "server_optimizer = optim.Adam(server_model.parameters(), lr=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "id": "b95b8d49-474d-4f5b-9c75-acf62b85ff87",
   "metadata": {},
   "outputs": [],
   "source": [
    "R=-1\n",
    "LR=0.01\n",
    "EPOCHS = 20\n",
    "criterion = nn.KLDivLoss(reduction=\"batchmean\")\n",
    "up = 1.1\n",
    "targetProb = 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "id": "16ef8c80-90b5-478d-9b7b-18095f4135a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterionCE = nn.CrossEntropyLoss()    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2068c674",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: 97.3% Server model accuracy on test set: 94.60%, local models average accuracy before copying: 66.10%\n"
     ]
    }
   ],
   "source": [
    "for r in range(2):\n",
    "    Pmax=[]\n",
    "    local_acc = []\n",
    "    for i, (model, loader, opt) in enumerate(zip(local_models, client_loaders, local_optimizers)):\n",
    "        train_local(model, loader, opt, device, epochs=EPOCHS, r=R, lr=LR)\n",
    "        if i % 5 == 0:\n",
    "            local_acc.append(evaluate(model, test_loader, device))\n",
    "\n",
    "    # EPOCHS=1\n",
    "    # LR=0.001\n",
    "    # R=-1\n",
    "    common_data = []\n",
    "    avg_logits = []\n",
    "    entropies = []\n",
    "    \n",
    "    server_model.train()    \n",
    "    for model in local_models:\n",
    "        model.eval()\n",
    "\n",
    "    cor = 0\n",
    "    tot = 0\n",
    "    for x, y in common_loader:\n",
    "        #for _ in range(common_data_size):\n",
    "            #x = torch.randn(batch_size, 1, 28, 28, device=device)\n",
    "            x = x.to(device)\n",
    "            common_data.append(x)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                local_logits = [m(x).detach() for m in local_models]\n",
    "                stacked = torch.stack(local_logits)\n",
    "                probs = F.softmax(stacked, dim=-1) \n",
    "                SEL=(torch.max(probs,-1)[0]<targetProb)\n",
    "                P = probs+0.0\n",
    "                P[SEL] *=0\n",
    "                P = torch.sum(P,axis=0)\n",
    "                S=torch.sum(P,1)\n",
    "                SEL = S>0\n",
    "                P = P[SEL] * (1/(S[SEL])).view([-1,1])\n",
    "                Pmax.append(torch.max(P,1)[0].data.cpu())\n",
    "            if torch.sum(SEL)>0:\n",
    "                pred = P.argmax(dim=1, keepdim=True)\n",
    "    \n",
    "                server_optimizer.zero_grad()\n",
    "\n",
    "                \n",
    "                # log_prob = F.log_softmax(server_model(x[SEL]), dim=-1)\n",
    "                # loss = criterion(log_prob, P )\n",
    "\n",
    "                output = server_model(x[SEL])\n",
    "                loss = criterionCE(output, pred.squeeze())\n",
    "                \n",
    "                loss.backward()\n",
    "                server_optimizer.step()\n",
    "                pred = pred.cpu()\n",
    "                cor += pred.eq(y[SEL.cpu()].view_as(pred)).sum().item()\n",
    "                tot += len(y[SEL.cpu()])\n",
    "\n",
    "    targetProb *= up\n",
    "    if targetProb > 0.9:\n",
    "        targetProb = 0.9\n",
    "\n",
    "    \n",
    "    acc = evaluate(server_model, test_loader, device)\n",
    "    print(f\"{r + 1}: {cor/tot*100}% Server model accuracy on test set: {acc*100:.2f}%, local models average accuracy before copying: {np.mean(local_acc)*100:.2f}%\")\n",
    "    for model in local_models:\n",
    "        model.load_state_dict(server_model.state_dict())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165c6d09-5617-4d50-ad6c-b47e1bd4793a",
   "metadata": {},
   "outputs": [],
   "source": [
    ".70+0.3*0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03571547-c81f-46a2-a720-d55609200a9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295deb7b-4045-4454-9c71-2a76cc86759c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfeef4e0-c9fe-4d4d-ab02-5fc2cbd7014b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4298aeca-f0e5-420f-adb2-720c0827413b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "id": "e90687e5-7388-482a-b307-22fc08cf273a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: 83.63889533534463% Server model accuracy on test set: 82.30%, local models average accuracy before copying: 84.05%\n",
      "2: 83.38148618976078% Server model accuracy on test set: 82.20%, local models average accuracy before copying: 83.10%\n",
      "3: 83.7571780147662% Server model accuracy on test set: 82.40%, local models average accuracy before copying: 82.80%\n",
      "4: 83.45724907063197% Server model accuracy on test set: 83.40%, local models average accuracy before copying: 83.35%\n",
      "47: 83.9041496201052% Server model accuracy on test set: 81.00%, local models average accuracy before copying: 81.80%\n",
      "48: 83.91436593355171% Server model accuracy on test set: 81.40%, local models average accuracy before copying: 81.75%\n",
      "49: 84.22279189000234% Server model accuracy on test set: 81.90%, local models average accuracy before copying: 82.15%\n",
      "50: 84.11149825783973% Server model accuracy on test set: 82.00%, local models average accuracy before copying: 82.40%\n",
      "51: 84.09459772779968% Server model accuracy on test set: 83.50%, local models average accuracy before copying: 82.40%\n",
      "52: 84.34184446776261% Server model accuracy on test set: 83.10%, local models average accuracy before copying: 83.45%\n",
      "53: 84.18283843815759% Server model accuracy on test set: 82.10%, local models average accuracy before copying: 83.05%\n",
      "54: 84.90521606028494% Server model accuracy on test set: 82.20%, local models average accuracy before copying: 82.65%\n",
      "55: 85.29860377801243% Server model accuracy on test set: 83.50%, local models average accuracy before copying: 83.00%\n",
      "56: 85.10142224294708% Server model accuracy on test set: 82.00%, local models average accuracy before copying: 83.60%\n",
      "57: 84.31326709526593% Server model accuracy on test set: 82.40%, local models average accuracy before copying: 82.95%\n",
      "58: 85.49216740706103% Server model accuracy on test set: 82.60%, local models average accuracy before copying: 82.85%\n",
      "59: 85.52004648460198% Server model accuracy on test set: 83.70%, local models average accuracy before copying: 83.25%\n",
      "60: 85.84994138335287% Server model accuracy on test set: 84.60%, local models average accuracy before copying: 84.10%\n",
      "61: 85.8611825192802% Server model accuracy on test set: 84.70%, local models average accuracy before copying: 84.95%\n",
      "62: 85.83690987124464% Server model accuracy on test set: 85.10%, local models average accuracy before copying: 84.85%\n",
      "63: 86.10177350179669% Server model accuracy on test set: 85.10%, local models average accuracy before copying: 85.10%\n",
      "64: 86.26444159178433% Server model accuracy on test set: 84.40%, local models average accuracy before copying: 85.50%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[475], line 52\u001b[0m\n\u001b[1;32m     49\u001b[0m output \u001b[38;5;241m=\u001b[39m server_model(x[SEL])\n\u001b[1;32m     50\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterionCE(output, pred\u001b[38;5;241m.\u001b[39msqueeze())\n\u001b[0;32m---> 52\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m server_optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     54\u001b[0m pred \u001b[38;5;241m=\u001b[39m pred\u001b[38;5;241m.\u001b[39mcpu()\n",
      "File \u001b[0;32m~/.conda/envs/fair-chem/lib/python3.11/site-packages/torch/_tensor.py:647\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    637\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    638\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    639\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    640\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    645\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    646\u001b[0m     )\n\u001b[0;32m--> 647\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    648\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    649\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/fair-chem/lib/python3.11/site-packages/torch/autograd/__init__.py:354\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    349\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    351\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    353\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 354\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    356\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    357\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    359\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_tuple\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    360\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    361\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    362\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/fair-chem/lib/python3.11/site-packages/torch/autograd/graph.py:829\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    827\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    828\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 829\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    830\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    831\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    833\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for r in range(100):\n",
    "    Pmax=[]\n",
    "    local_acc = []\n",
    "    for i, (model, loader, opt) in enumerate(zip(local_models, client_loaders, local_optimizers)):\n",
    "        train_local(model, loader, opt, device, epochs=EPOCHS, r=R, lr=LR)\n",
    "        if i % 5 == 0:\n",
    "            local_acc.append(evaluate(model, test_loader, device))\n",
    "\n",
    "    EPOCHS=1\n",
    "    # LR=0.001\n",
    "    # R=-1\n",
    "    common_data = []\n",
    "    avg_logits = []\n",
    "    entropies = []\n",
    "    \n",
    "    server_model.train()    \n",
    "    for model in local_models:\n",
    "        model.eval()\n",
    "\n",
    "    cor = 0\n",
    "    tot = 0\n",
    "    for x, y in common_loader:\n",
    "        #for _ in range(common_data_size):\n",
    "            #x = torch.randn(batch_size, 1, 28, 28, device=device)\n",
    "            x = x.to(device)\n",
    "            common_data.append(x)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                local_logits = [m(x).detach() for m in local_models]\n",
    "                stacked = torch.stack(local_logits)\n",
    "                probs = F.softmax(stacked, dim=-1) \n",
    "                SEL=(torch.max(probs,-1)[0]<targetProb)\n",
    "                P = probs+0.0\n",
    "                P[SEL] *=0\n",
    "                P = torch.sum(P,axis=0)\n",
    "                S=torch.sum(P,1)\n",
    "                SEL = S>0\n",
    "                P = P[SEL] * (1/(S[SEL])).view([-1,1])\n",
    "                Pmax.append(torch.max(P,1)[0].data.cpu())\n",
    "            if torch.sum(SEL)>0:\n",
    "                pred = P.argmax(dim=1, keepdim=True)\n",
    "    \n",
    "                server_optimizer.zero_grad()\n",
    "\n",
    "                \n",
    "                # log_prob = F.log_softmax(server_model(x[SEL]), dim=-1)\n",
    "                # loss = criterion(log_prob, P )\n",
    "\n",
    "                output = server_model(x[SEL])\n",
    "                loss = criterionCE(output, pred.squeeze())\n",
    "                \n",
    "                loss.backward()\n",
    "                server_optimizer.step()\n",
    "                pred = pred.cpu()\n",
    "                cor += pred.eq(y[SEL.cpu()].view_as(pred)).sum().item()\n",
    "                tot += len(y[SEL.cpu()])\n",
    "\n",
    "    targetProb *= up\n",
    "    if targetProb > 0.9:\n",
    "        targetProb = 0.9\n",
    "\n",
    "    \n",
    "    acc = evaluate(server_model, test_loader, device)\n",
    "    print(f\"{r + 1}: {cor/tot*100}% Server model accuracy on test set: {acc*100:.2f}%, local models average accuracy before copying: {np.mean(local_acc)*100:.2f}%\")\n",
    "    for model in local_models:\n",
    "        model.load_state_dict(server_model.state_dict())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "id": "7a5dac4c-b0ee-4eb4-8f41-2a87e1956f91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.3201, device='cuda:0', grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 467,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterionCE(output, pred.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "id": "286c6dcf-1ec5-4a06-a171-c6183d0b5cb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(torch.cat(Pmax));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e67ace3-e916-4126-b476-6610d01823ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "id": "c0d9b7a0-23e4-48ee-b7de-9e11e8587d1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy centralized 0.911\n",
      "accuracy centralized 0.955\n",
      "accuracy centralized 0.961\n",
      "accuracy centralized 0.963\n",
      "accuracy centralized 0.969\n",
      "accuracy centralized 0.955\n",
      "accuracy centralized 0.963\n",
      "accuracy centralized 0.973\n",
      "accuracy centralized 0.97\n",
      "accuracy centralized 0.974\n"
     ]
    }
   ],
   "source": [
    "centralized = SimpleCNN().to(device)\n",
    "\n",
    "centralized_optimizer = optim.Adam(centralized.parameters(), lr=0.01)\n",
    "model.train()\n",
    "criterion = nn.CrossEntropyLoss()    \n",
    "\n",
    "for _ in range(10):\n",
    "    for j, (data, target) in enumerate(common_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        centralized_optimizer.zero_grad()\n",
    "        output = centralized(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        centralized_optimizer.step()\n",
    "    acc = evaluate(centralized, test_loader, device)\n",
    "    print(\"accuracy centralized\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "eeac16d9-ad18-4a9f-8576-407795a0d8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b8d800-0414-4650-9804-324e1cac0dca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b9b4b4-e039-4c67-90df-fccea6feec0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "78808d83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.068"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "68be3763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.068\n",
      "0.068\n",
      "0.068\n",
      "0.068\n",
      "0.068\n",
      "0.068\n",
      "0.068\n",
      "0.068\n",
      "0.068\n",
      "0.068\n"
     ]
    }
   ],
   "source": [
    "for model in local_models:\n",
    "    model.load_state_dict(server_model.state_dict())\n",
    "    acc = evaluate(model, test_loader, device)\n",
    "    print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "becd6cdb-333d-4ab1-85fc-ae163647a387",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_local(model, common_loader, opt, device, epochs=1, r=-1, lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "735afc92-abc5-429f-9df5-6c3ea2c55700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.935\n"
     ]
    }
   ],
   "source": [
    "acc = evaluate(model, test_loader, device)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "dc12cde4-3c69-4a3f-8904-e79e1a6dc48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_local(model, client_loaders[-1], opt, device, epochs=1, r=-1, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "684fab1a-4227-49dd-8d39-5556dd4518dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.687\n"
     ]
    }
   ],
   "source": [
    "acc = evaluate(model, test_loader, device)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6635442a-1568-4c6a-98fb-38a164ef5f69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddddab1a-2520-4df4-bcee-241105ed89d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
