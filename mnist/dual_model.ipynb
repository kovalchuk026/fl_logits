{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1261199a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import numpy as np\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "329d0e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:4\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9e726299",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, 3, padding=1)\n",
    "        self.fc = nn.Linear(16 * 28 * 28, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = x.view(-1, 16 * 28 * 28)\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "872b1466",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_probabilistic_client_loaders(num_clients=20, p=0.7, batch_size=32):\n",
    "    \"\"\"\n",
    "    Create client loaders for MNIST:\n",
    "    - First take out a common dataset of size `common_size`.\n",
    "    - Each class is assigned to each client with probability p.\n",
    "    - Class samples are split among selected clients (no overlap).\n",
    "    \"\"\"\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ])\n",
    "\n",
    "    dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "    # Build class indices from remaining dataset\n",
    "    class_indices = defaultdict(list)\n",
    "    for idx, (_, label) in enumerate(dataset):\n",
    "        class_indices[label].append(idx)\n",
    "    for c in class_indices:\n",
    "        np.random.shuffle(class_indices[c])\n",
    "\n",
    "    client_indices = [[] for _ in range(num_clients)]\n",
    "\n",
    "    for class_idx in range(10):\n",
    "        # Determine which clients get this class\n",
    "        client_mask = np.random.rand(num_clients) < p\n",
    "        selected_clients = np.where(client_mask)[0]\n",
    "\n",
    "        if len(selected_clients) > 0:\n",
    "            # Split class indices among selected clients\n",
    "            splits = np.array_split(class_indices[class_idx], len(selected_clients))\n",
    "            for client_id, split in zip(selected_clients, splits):\n",
    "                client_indices[client_id].extend(split)\n",
    "\n",
    "    # Create DataLoaders for clients\n",
    "    client_loaders = []\n",
    "    for indices in client_indices:\n",
    "        if not indices:\n",
    "            indices = [0]  # fallback if client gets no data\n",
    "        loader = DataLoader(\n",
    "            Subset(dataset, indices),\n",
    "            batch_size=batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=2,\n",
    "            pin_memory=True,\n",
    "            drop_last=True\n",
    "        )\n",
    "        client_loaders.append(loader)\n",
    "\n",
    "    return client_loaders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5e42f238",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_local_data(model, loader, optimizer, device, epochs=1):\n",
    "    model.train()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    if not optimizer:\n",
    "        optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "    for _ in range(epochs):\n",
    "        for data, target in loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "352fa6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_common_data(model, avg_logits, common_data, optimizer, epochs=1):\n",
    "    model.train()\n",
    "    criterion = nn.MSELoss()\n",
    "    if not optimizer:\n",
    "        optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "    for _ in range(epochs):\n",
    "        for x, y in zip(common_data, avg_logits):\n",
    "            optimizer.zero_grad()\n",
    "            server_logits = model(x)\n",
    "            loss = criterion(server_logits, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f57793ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_loader, device):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "            total += target.size(0)\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "31c71257",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_clients = 10\n",
    "batch_size = 128\n",
    "common_data_size = 512\n",
    "client_loaders = create_probabilistic_client_loaders(num_clients, batch_size=batch_size, p=0.2)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=2, pin_memory=True, drop_last=True)\n",
    "\n",
    "local_data_models = [SimpleCNN().to(device) for _ in range(num_clients)]\n",
    "common_data_models = [SimpleCNN().to(device) for _ in range(num_clients)]\n",
    "\n",
    "optimizers = [optim.Adam(m.parameters(), lr=0.0001) for m in local_data_models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2068c674",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: Server model accuracy on test set: 11.61%\n",
      "\n",
      "1: Server model accuracy on test set: 16.11%\n",
      "\n",
      "2: Server model accuracy on test set: 17.89%\n",
      "\n",
      "3: Server model accuracy on test set: 18.51%\n",
      "\n",
      "4: Server model accuracy on test set: 18.67%\n",
      "\n",
      "5: Server model accuracy on test set: 18.98%\n",
      "\n",
      "6: Server model accuracy on test set: 19.32%\n",
      "\n",
      "7: Server model accuracy on test set: 19.67%\n",
      "\n",
      "8: Server model accuracy on test set: 19.88%\n",
      "\n",
      "9: Server model accuracy on test set: 20.29%\n",
      "\n",
      "10: Server model accuracy on test set: 20.53%\n",
      "\n",
      "11: Server model accuracy on test set: 20.80%\n",
      "\n",
      "12: Server model accuracy on test set: 21.10%\n",
      "\n",
      "13: Server model accuracy on test set: 21.45%\n",
      "\n",
      "14: Server model accuracy on test set: 21.67%\n",
      "\n",
      "15: Server model accuracy on test set: 21.91%\n",
      "\n",
      "16: Server model accuracy on test set: 22.03%\n",
      "\n",
      "17: Server model accuracy on test set: 22.23%\n",
      "\n",
      "18: Server model accuracy on test set: 22.42%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for r in range(50):\n",
    "    for i, (model, loader, opt) in enumerate(zip(local_data_models, client_loaders, optimizers)):\n",
    "        train_local_data(model, loader, None, device, epochs=1)\n",
    "\n",
    "    common_data = []\n",
    "    avg_logits = []\n",
    "\n",
    "    for _ in range(common_data_size):\n",
    "        x = torch.randn(batch_size, 1, 28, 28, device=device)\n",
    "        common_data.append(x)\n",
    "        with torch.no_grad():\n",
    "            local_logits = [m(x).detach() for m in local_data_models]\n",
    "            avg_logits.append(torch.mean(torch.stack(local_logits), dim=0))\n",
    "    common_data = torch.stack(common_data)\n",
    "\n",
    "    accs = []\n",
    "    for m, opt in zip(common_data_models, optimizers):\n",
    "        train_common_data(m, avg_logits, common_data, None, epochs=1)\n",
    "        acc = evaluate(m, test_loader, device)\n",
    "    \n",
    "    for local_data_model, common_data_model in zip(local_data_models, common_data_models):\n",
    "        local_data_model.load_state_dict(common_data_model.state_dict())\n",
    "\n",
    "    print(f\"{r}: Server model accuracy on test set: {np.mean(acc)*100:.2f}%\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78808d83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68be3763",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv (3.12.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
