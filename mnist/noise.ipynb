{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1261199a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import numpy as np\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "329d0e2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f57840f8190>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = 0\n",
    "device = torch.device(\"cuda:4\" if torch.cuda.is_available() else \"cpu\")\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9e726299",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, 3, padding=1)\n",
    "        self.fc = nn.Linear(16 * 28 * 28, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = x.view(-1, 16 * 28 * 28)\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "872b1466",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_fixed_class_client_loaders(num_clients=20, k=2, batch_size=32):  #checked\n",
    "    \n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ])\n",
    "\n",
    "    dataset = datasets.MNIST(root=\"./data\", train=True, download=True, transform=transform)\n",
    "\n",
    "    # Build class indices\n",
    "    class_indices = defaultdict(list)\n",
    "    for idx, (_, label) in enumerate(dataset):\n",
    "        class_indices[label].append(idx)\n",
    "    \n",
    "    for c in class_indices:\n",
    "        np.random.shuffle(class_indices[c])\n",
    "\n",
    "    # Assign exactly k unique classes to each client\n",
    "    all_classes = np.arange(10)\n",
    "    client_classes = [np.random.choice(all_classes, size=k, replace=False) for _ in range(num_clients)]\n",
    "\n",
    "    client_indices = [[] for _ in range(num_clients)]\n",
    "\n",
    "    # Distribute samples of each class to clients that need it\n",
    "    for class_id in range(10):\n",
    "    \n",
    "        # Clients that selected this class\n",
    "        clients_with_class = [cid for cid, classes in enumerate(client_classes) if class_id in classes]\n",
    "        if not clients_with_class:\n",
    "            continue\n",
    "\n",
    "        # Split class data among those clients\n",
    "        splits = np.array_split(class_indices[class_id], len(clients_with_class))\n",
    "        for cid, split in zip(clients_with_class, splits):\n",
    "            client_indices[cid].extend(split.tolist())\n",
    "\n",
    "    client_loaders = []\n",
    "    for indices in client_indices:\n",
    "        if not indices:\n",
    "            indices = [0] \n",
    "        loader = DataLoader(\n",
    "            Subset(dataset, indices),\n",
    "            batch_size=batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=2,\n",
    "            pin_memory=True,\n",
    "            drop_last=True\n",
    "        )\n",
    "        client_loaders.append(loader)\n",
    "    return client_loaders, client_classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5e42f238",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_local(model, loader, optimizer, device, epochs=1): #checked\n",
    "    model.train()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "    for _ in range(epochs):\n",
    "        for data, target in loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "352fa6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_server(server_model, avg_logits, common_data, optimizer, epochs=1): #checked\n",
    "    server_model.train()\n",
    "    criterion = nn.KLDivLoss(reduction=\"batchmean\")\n",
    "\n",
    "    for _ in range(epochs):\n",
    "        for x, y in zip(common_data, avg_logits):\n",
    "            optimizer.zero_grad()\n",
    "            log_prob = F.log_softmax(server_model(x), dim=-1)\n",
    "            loss = criterion(log_prob, F.softmax(y, dim=-1))\n",
    "            loss.backward()\n",
    "            optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f57793ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_loader, device): #checked\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "            total += target.size(0)\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "77d95ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_out_uncertain_logits(logits_list, threshold=1.2):  #checked\n",
    "    stacked = torch.stack(logits_list)        # [M, B, C]\n",
    "    # Compute entropy per model per sample\n",
    "    probs = F.softmax(stacked, dim=-1)        # [M, B, C]\n",
    "    entropy = -(probs * probs.log()).sum(dim=-1)   # [M, B]\n",
    "\n",
    "    # Mask: True if confident\n",
    "    mask = (entropy < threshold).float()      # [M, B]\n",
    "\n",
    "    # Expand mask to logits shape\n",
    "    mask_expanded = mask.unsqueeze(-1)        # [M, B, 1]\n",
    "\n",
    "    # Zero out uncertain logits\n",
    "    masked_logits = stacked * mask_expanded   # [M, B, C]\n",
    "\n",
    "    # Count how many models contributed per sample\n",
    "    denom = mask.sum(dim=0).unsqueeze(-1).clamp(min=1)  # [B, 1]\n",
    "\n",
    "    # Average only over confident models\n",
    "    avg_logits = masked_logits.sum(dim=0) / denom       # [B, C]\n",
    "    return avg_logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "31c71257",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_clients = 30\n",
    "batch_size = 128\n",
    "common_data_size = 512\n",
    "k = 2\n",
    "threshold = 3\n",
    "\n",
    "client_loaders, _ = create_fixed_class_client_loaders(num_clients, batch_size=batch_size, k=k)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=2, pin_memory=True, drop_last=True)\n",
    "\n",
    "local_models = [SimpleCNN().to(device) for _ in range(num_clients)]\n",
    "server_model = SimpleCNN().to(device)\n",
    "\n",
    "local_optimizers = [optim.Adam(m.parameters(), lr=0.001) for m in local_models]\n",
    "server_optimizer = optim.SGD(server_model.parameters(), lr=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2068c674",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: Server model accuracy on test set: 26.61%\n",
      "\n",
      "2: Server model accuracy on test set: 43.93%\n",
      "\n",
      "3: Server model accuracy on test set: 44.80%\n",
      "\n",
      "4: Server model accuracy on test set: 53.53%\n",
      "\n",
      "5: Server model accuracy on test set: 53.55%\n",
      "\n",
      "6: Server model accuracy on test set: 57.79%\n",
      "\n",
      "7: Server model accuracy on test set: 59.34%\n",
      "\n",
      "8: Server model accuracy on test set: 63.27%\n",
      "\n",
      "9: Server model accuracy on test set: 65.37%\n",
      "\n",
      "10: Server model accuracy on test set: 67.08%\n",
      "\n",
      "11: Server model accuracy on test set: 68.83%\n",
      "\n",
      "12: Server model accuracy on test set: 70.28%\n",
      "\n",
      "13: Server model accuracy on test set: 71.35%\n",
      "\n",
      "14: Server model accuracy on test set: 72.42%\n",
      "\n",
      "15: Server model accuracy on test set: 72.97%\n",
      "\n",
      "16: Server model accuracy on test set: 72.91%\n",
      "\n",
      "17: Server model accuracy on test set: 74.13%\n",
      "\n",
      "18: Server model accuracy on test set: 75.29%\n",
      "\n",
      "19: Server model accuracy on test set: 75.53%\n",
      "\n",
      "20: Server model accuracy on test set: 75.51%\n",
      "\n",
      "21: Server model accuracy on test set: 76.97%\n",
      "\n",
      "22: Server model accuracy on test set: 76.53%\n",
      "\n",
      "23: Server model accuracy on test set: 77.52%\n",
      "\n",
      "24: Server model accuracy on test set: 78.18%\n",
      "\n",
      "25: Server model accuracy on test set: 78.28%\n",
      "\n",
      "26: Server model accuracy on test set: 78.72%\n",
      "\n",
      "27: Server model accuracy on test set: 78.69%\n",
      "\n",
      "28: Server model accuracy on test set: 79.08%\n",
      "\n",
      "29: Server model accuracy on test set: 79.45%\n",
      "\n",
      "30: Server model accuracy on test set: 79.96%\n",
      "\n",
      "31: Server model accuracy on test set: 80.13%\n",
      "\n",
      "32: Server model accuracy on test set: 80.36%\n",
      "\n",
      "33: Server model accuracy on test set: 80.64%\n",
      "\n",
      "34: Server model accuracy on test set: 80.52%\n",
      "\n",
      "35: Server model accuracy on test set: 81.13%\n",
      "\n",
      "36: Server model accuracy on test set: 81.26%\n",
      "\n",
      "37: Server model accuracy on test set: 81.41%\n",
      "\n",
      "38: Server model accuracy on test set: 81.07%\n",
      "\n",
      "39: Server model accuracy on test set: 81.53%\n",
      "\n",
      "40: Server model accuracy on test set: 81.80%\n",
      "\n",
      "41: Server model accuracy on test set: 82.13%\n",
      "\n",
      "42: Server model accuracy on test set: 82.11%\n",
      "\n",
      "43: Server model accuracy on test set: 82.10%\n",
      "\n",
      "44: Server model accuracy on test set: 82.17%\n",
      "\n",
      "45: Server model accuracy on test set: 82.41%\n",
      "\n",
      "46: Server model accuracy on test set: 82.50%\n",
      "\n",
      "47: Server model accuracy on test set: 82.55%\n",
      "\n",
      "48: Server model accuracy on test set: 82.79%\n",
      "\n",
      "49: Server model accuracy on test set: 82.69%\n",
      "\n",
      "50: Server model accuracy on test set: 83.15%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for r in range(50):\n",
    "    for i, (model, loader, opt) in enumerate(zip(local_models, client_loaders, local_optimizers)):\n",
    "        train_local(model, loader, opt, device, epochs=1)\n",
    "\n",
    "    common_data = []\n",
    "    avg_logits = []\n",
    "\n",
    "    for _ in range(common_data_size):\n",
    "        x = torch.randn(batch_size, 1, 28, 28, device=device)\n",
    "        common_data.append(x)\n",
    "        with torch.no_grad():\n",
    "            local_logits = [m(x).detach() for m in local_models]\n",
    "            avg_logits.append(zero_out_uncertain_logits(local_logits, threshold=threshold))\n",
    "            \n",
    "    common_data = torch.stack(common_data)\n",
    "    train_server(server_model, avg_logits, common_data, server_optimizer, epochs=1)\n",
    "    for model in local_models:\n",
    "        model.load_state_dict(server_model.state_dict())\n",
    "\n",
    "    acc = evaluate(server_model, test_loader, device)\n",
    "    print(f\"{r + 1}: Server model accuracy on test set: {acc*100:.2f}%\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78808d83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68be3763",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.12.5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
